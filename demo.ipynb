{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo, we demonstrate how to use the MaxEnt_Reg script. We will be going over how to do the following:\n",
    "\n",
    "1. Reading in the MaxEnt data and constraint information\n",
    "2. Running the model using different gradient descent techniques (without regularization)\n",
    "3. How to add regularization \n",
    "    * Target prior ```TGTPrior``` \n",
    "    * Difference prior ```DIFPrior```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Good old NumPy\n",
    "import numpy as np\n",
    "\n",
    "## Specialized classes\n",
    "from utils.MaxEnt import MaxEnt, compute_probabilities\n",
    "from utils.Regularization import TGTPrior, DIFPrior\n",
    "\n",
    "## Utility function for reading in constraint and data information\n",
    "from utils.OTSoft_file_reader import get_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def prob_prediction_to_csv(file_name, underlying_forms, candidates, violations, weights):\n",
    "    with open(file_name, \"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"UR/Candidate\", \"Probability\"])\n",
    "        for t, vio in enumerate(violations):\n",
    "            P = compute_probabilities(weights.squeeze(), vio)\n",
    "            writer.writerow([underlying_forms[t]])\n",
    "            \n",
    "            for c, _ in enumerate(candidates[t]):\n",
    "                writer.writerow([candidates[t][c], f\"{round(P[c]*100, 1)}%\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demonstration, we will be looking at the Hayes Pseudo-Korean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constraint names and their initial weights:\n",
      "Ident (asp)          7.5\n",
      "Ident (voice)        2.25\n",
      "Ident (asp)/_V       3.97\n",
      "Ident (voice)/_V     3.16\n",
      "*[+v][-v][+v]        8.08\n",
      "*dh                  8.89\n",
      "*[-son/+voice]       4.94\n",
      "*aspiration          7.28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Read in data and constraint information\n",
    "constraint_names, underlying_forms, candidates, violations, observed_probs = get_info(\n",
    "    \"toy_datasets/HayesPseudoKorean-RichBase.txt\"\n",
    ")\n",
    "\n",
    "## Initialize a MaxEnt object\n",
    "me = MaxEnt(constraint_names)\n",
    "\n",
    "## Print basic information\n",
    "print(f\"Constraint names and their initial weights:\")\n",
    "for cn in zip(constraint_names, me.cws):\n",
    "    print(f'{cn[0]:<20} {round(cn[1][0], 2)}')\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights after learning:\n",
      "Ident (asp)          8.01\n",
      "Ident (voice)        2.3\n",
      "Ident (asp)/_V       4.48\n",
      "Ident (voice)/_V     3.19\n",
      "*[+v][-v][+v]        8.07\n",
      "*dh                  8.89\n",
      "*[-son/+voice]       4.98\n",
      "*aspiration          6.77\n",
      "\n",
      "Predicted probabilities saved to results/no_reg_pred.csv\n"
     ]
    }
   ],
   "source": [
    "## Perform learning without regularization and returns the final weights\n",
    "new_weights, learning_history = me.SGD_learn(violations=violations, observed_prob=observed_probs)\n",
    "\n",
    "print(\"Weights after learning:\")\n",
    "for cn in zip(constraint_names, new_weights):\n",
    "    print(f'{cn[0]:<20} {round(cn[1][0], 2)}')\n",
    "print()\n",
    "\n",
    "file_name = \"results/no_reg_pred.csv\"\n",
    "prob_prediction_to_csv(file_name, underlying_forms, candidates, violations, new_weights)\n",
    "print(f\"Predicted probabilities saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights after learning:\n",
      "Ident (asp)          1.68\n",
      "Ident (voice)        1.05\n",
      "Ident (asp)/_V       1.68\n",
      "Ident (voice)/_V     1.05\n",
      "*[+v][-v][+v]        10.0\n",
      "*dh                  10.0\n",
      "*[-son/+voice]       10.0\n",
      "*aspiration          9.32\n",
      "\n",
      "Predicted probabilities saved to results/TGT_pred.tsv\n"
     ]
    }
   ],
   "source": [
    "## M >> F TGT\n",
    "cns = constraint_names\n",
    "grs = [\n",
    "    [\"Ident (asp)\", \"Ident (voice)\", \"Ident (asp)/_V\", \"Ident (voice)/_V\"], \n",
    "    [\"*[+v][-v][+v]\", \"*dh\", \"*[-son/+voice]\",\"*aspiration\"]\n",
    "]\n",
    "mus = [1, 10]\n",
    "sms = [1, 1]\n",
    "target_prior = TGTPrior(cns, grs, mus, sms)\n",
    "\n",
    "## Perform learning with regularization and returns the final weights\n",
    "new_weights, learning_history = me.SGD_learn(violations, observed_probs, 1, 10000, 0.05, target_prior)\n",
    "\n",
    "print(\"Weights after learning:\")\n",
    "for cn in zip(cns, new_weights):\n",
    "    print(f'{cn[0]:<20} {round(cn[1][0], 2)}')\n",
    "print()\n",
    "\n",
    "file_name = \"results/TGT_pred.csv\"\n",
    "prob_prediction_to_csv(file_name, underlying_forms, candidates, violations, new_weights)\n",
    "print(f\"Predicted probabilities saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights after learning:\n",
      "Ident (asp)          9.67\n",
      "Ident (voice)        4.44\n",
      "Ident (asp)/_V       6.14\n",
      "Ident (voice)/_V     5.32\n",
      "*[+v][-v][+v]        5.92\n",
      "*dh                  6.73\n",
      "*[-son/+voice]       2.81\n",
      "*aspiration          5.11\n",
      "\n",
      "Predicted probabilities saved to results/DIF_pred_1.csv\n"
     ]
    }
   ],
   "source": [
    "## M >> F DIF\n",
    "cns = constraint_names\n",
    "grs = [\n",
    "    [\"Ident (asp)\", \"Ident (voice)\", \"Ident (asp)/_V\", \"Ident (voice)/_V\"], \n",
    "    [\"*[+v][-v][+v]\", \"*dh\", \"*[-son/+voice]\",\"*aspiration\"]\n",
    "]\n",
    "mus = [5]\n",
    "sms = [3]\n",
    "msg = [[0, 1]]\n",
    "diff_prior = DIFPrior(cns, grs, mus, sms, msg)\n",
    "\n",
    "## Perform learning with regularization and returns the final weights\n",
    "new_weights, learning_history = me.SGD_learn(violations, observed_probs, 1, 10000, 0.05, diff_prior)\n",
    "\n",
    "print(\"Weights after learning:\")\n",
    "for cn in zip(cns, new_weights):\n",
    "    print(f'{cn[0]:<20} {round(cn[1][0], 2)}')\n",
    "print()\n",
    "\n",
    "file_name = \"results/DIF_pred_1.csv\"\n",
    "prob_prediction_to_csv(file_name, underlying_forms, candidates, violations, new_weights)\n",
    "print(f\"Predicted probabilities saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights after learning:\n",
      "Ident (asp)          13.8\n",
      "Ident (voice)        10.8\n",
      "Ident (asp)/_V       7.81\n",
      "Ident (voice)/_V     4.83\n",
      "*[+v][-v][+v]        0.0\n",
      "*dh                  0.0\n",
      "*[-son/+voice]       0.0\n",
      "*aspiration          0.0\n",
      "\n",
      "Predicted probabilities saved to results/DIF_pred_2.csv\n"
     ]
    }
   ],
   "source": [
    "## M >> F DIF\n",
    "cns = constraint_names\n",
    "grs = [\n",
    "    [\"Ident (asp)\"], \n",
    "    [\"Ident (voice)\"], \n",
    "    [\"Ident (asp)/_V\"], \n",
    "    [\"Ident (voice)/_V\"], \n",
    "    [\"*[+v][-v][+v]\", \"*dh\", \"*[-son/+voice]\", \"*aspiration\"]\n",
    "]\n",
    "mus = [3, 3, 3, 5]\n",
    "sms = [1, 1, 1, 3]\n",
    "msg = [[0, 1], [1, 2], [2, 3], [3, 4]]\n",
    "diff_prior = DIFPrior(cns, grs, mus, sms, msg)\n",
    "\n",
    "## Perform learning with regularization and returns the final weights\n",
    "new_weights, learning_history = me.SGD_learn(violations, observed_probs, 1, 10000, 0.05, diff_prior)\n",
    "\n",
    "print(\"Weights after learning:\")\n",
    "for cn in zip(cns, new_weights):\n",
    "    print(f'{cn[0]:<20} {round(cn[1][0], 2)}')\n",
    "print()\n",
    "\n",
    "file_name = \"results/DIF_pred_2.csv\"\n",
    "prob_prediction_to_csv(file_name, underlying_forms, candidates, violations, new_weights)\n",
    "print(f\"Predicted probabilities saved to {file_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
